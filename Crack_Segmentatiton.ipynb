{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3dQs/VUYiMMGkcKavvekE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melekbairamova20/melekbairamova20/blob/main/Crack_Segmentatiton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and preprocess dataset"
      ],
      "metadata": {
        "id": "7DUwNOOxH1lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CtCyWdjrIWxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/databyhuseyn/DeepLearning/refs/heads/main/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdHyaqUNIkn7",
        "outputId": "d2e01b10-bf7b-4bd0-ae53-269148124fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-02 13:49:49--  https://raw.githubusercontent.com/databyhuseyn/DeepLearning/refs/heads/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-02 13:49:50 (73.9 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import plot_loss_curves, unzip_data"
      ],
      "metadata": {
        "id": "a5WjuuF-I4s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data('/content/Conglomerate Concrete Crack Detection.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "inx0-BcSJDh6",
        "outputId": "7917ac45-7ff9-4c58-a808-06834d27b8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Conglomerate Concrete Crack Detection.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e477b6e05338>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munzip_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Conglomerate Concrete Crack Detection.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36munzip_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mzip\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0munzipped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m   \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m   \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m   \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Conglomerate Concrete Crack Detection.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 128, 128\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_images_dir = '/content/Conglomerate Concrete Crack Detection/Train/images'\n",
        "train_masks_dir = '/content/Conglomerate Concrete Crack Detection/Train/masks'\n",
        "test_images_dir  = '/content/Conglomerate Concrete Crack Detection/Test/images'\n",
        "test_masks_dir = '/content/Conglomerate Concrete Crack Detection/Test/masks'\n",
        "\n",
        "def load_data(image_dir, mask_dir, img_size):\n",
        "  images, masks = [], []\n",
        "\n",
        "  for filename in os.listdir(image_dir):\n",
        "    img = load_img(os.path.join(image_dir, filename), target_size = img_size)\n",
        "    img = img_to_array(img) / 255.0\n",
        "\n",
        "    mask = load_img(os.path.join(mask_dir, filename), target_size = img_size, color_mode = \"grayscale\")\n",
        "    mask = img_to_array(mask) / 255.0\n",
        "    masks.append(mask)\n",
        "\n",
        "  return np.array(images), np.array(masks)\n",
        "\n",
        "X_train, y_train = load_data(\n",
        "    train_images_dir,\n",
        "    train_masks_dir,\n",
        "    IMG_SIZE\n",
        ")\n",
        "\n",
        "X_test, y_test = load_data(\n",
        "    test_images_dir,\n",
        "    test_masks_dir,\n",
        "    IMG_SIZE\n",
        ")\n",
        "\n",
        "print(f'Train images shape: {X_train.shape}, Train masks shape: {y_train.shape}')\n",
        "print(f'Test images shape: {X_test.shape}, Test masks shape: {y_test.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "kBqFzYATJOF6",
        "outputId": "fc217cc0-7be1-4580-8e06-63c663a5bce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-19008513e36e>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m X_train, y_train = load_data(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_images_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_masks_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-19008513e36e>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(image_dir, mask_dir, img_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "8DtekPc_KI2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_images_dir = '/content/Conglomerate Concrete Crack Detection/Train/images'\n",
        "train_masks_dir = '/content/Conglomerate Concrete Crack Detection/Train/masks'\n",
        "\n",
        "image_files = os.listdir(train_images_dir)\n",
        "\n",
        "fig, axes = plt.subplot(nrows = 3, ncols = 3, figsize = (12, 12))\n",
        "\n",
        "for i in range(9):\n",
        "  n = np.random.randint(len(image_files))\n",
        "  image_path = os.path.join(train_images_dir, image_files[n])\n",
        "  mask_path = os.path.join(train_masks_dir, image_files[n])\n",
        "\n",
        "  img = plt.imread(image_path)\n",
        "  mask = plt.imread(mask_path)\n",
        "\n",
        "  ax = axes[i // 3, i % 3]\n",
        "  ax.imshow(img, cmpay = 'gray')\n",
        "  ax.imshow(mask, cmap = 'jet', alpha = 0.35)\n",
        "\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PyOLb94uOyju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model"
      ],
      "metadata": {
        "id": "2lE6TWVXRiho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def create_unet_model(input_shape=(128, 128, 3)):\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  conv2d_0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "  conv2d_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_0)            # birleshdir\n",
        "  max_pool_0 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv2d_1)\n",
        "  conv2d_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(max_pool_0)\n",
        "  conv2d_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_2)            # birleshdir\n",
        "  max_pool_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv2d_3)\n",
        "  conv2d_4 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(max_pool_1)\n",
        "  conv2d_5 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_4)            # birleshdir\n",
        "  max_pool_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv2d_5)\n",
        "  conv2d_6 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(max_pool_2)\n",
        "  conv2d_7 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_6)            # birleshdir\n",
        "  max_pool_3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv2d_7)\n",
        "  conv2d_8 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(max_pool_3)\n",
        "  conv2d_9 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_8)\n",
        "  up_conv_0 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=(2, 2), strides=(2, 2), padding='same')(conv2d_9)\n",
        "  up_conv_0_resized = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, size=(up_conv_0.shape[1], up_conv_0.shape[2])))(conv2d_7)\n",
        "\n",
        "  concat_0 = tf.keras.layers.concatenate([up_conv_0_resized, up_conv_0], axis=3)\n",
        "  conv2d_10 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat_0)\n",
        "  conv2d_11 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_10)\n",
        "  up_conv_1 = tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size=(2, 2), strides=(2, 2), padding='same')(conv2d_11)\n",
        "  up_conv_1_resized = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, size=(up_conv_1.shape[1], up_conv_1.shape[2])))(conv2d_5)\n",
        "\n",
        "  concat_1 = tf.keras.layers.concatenate([up_conv_1_resized, up_conv_1], axis=3)\n",
        "  conv2d_12 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat_1)\n",
        "  conv2d_13 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_12)\n",
        "  up_conv_2 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(2, 2), strides=(2, 2), padding='same')(conv2d_13)\n",
        "  up_conv_2_resized = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, size=(up_conv_2.shape[1], up_conv_2.shape[2])))(conv2d_3)\n",
        "\n",
        "  concat_2 = tf.keras.layers.concatenate([up_conv_2_resized, up_conv_2], axis=3)\n",
        "  conv2d_14 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat_2)\n",
        "  conv2d_15 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_14)\n",
        "  up_conv_3 = tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size=(2, 2), strides=(2, 2), padding='same')(conv2d_15)\n",
        "  up_conv_3_resized = tf.keras.layers.Lambda(lambda x: tf.image.resize(x, size=(up_conv_3.shape[1], up_conv_3.shape[2])))(conv2d_1)\n",
        "\n",
        "  concat_3 = tf.keras.layers.concatenate([up_conv_3_resized, up_conv_3], axis=3)\n",
        "  conv2d_16 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat_3)\n",
        "  conv2d_17 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_16)\n",
        "  conv2d_18 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2d_17)\n",
        "  outputs = tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(conv2d_18)\n",
        "\n",
        "  unet_model = tf.keras.Model(inputs, outputs, name='Unet-remake')\n",
        "  return unet_model"
      ],
      "metadata": {
        "id": "Il2-nw40RudW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdzHDHZxR7Ju",
        "outputId": "1beaa770-af31-40ae-d4ae-56f13ffe31f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model = create_unet_model(input_shape = input_shape)"
      ],
      "metadata": {
        "id": "n6KIqEAaSHls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.summary()"
      ],
      "metadata": {
        "id": "iXaSuJLbSSnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(unet_model, show_shapes = True)"
      ],
      "metadata": {
        "id": "3p6mAKWkS08c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's fit the model"
      ],
      "metadata": {
        "id": "yThCLVtOS6wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckp = tf.keras.callbacks.ModelCheckpoint('/content/best_model.weights.h5',\n",
        "                                               save_best_only = True,\n",
        "                                               save_weights_only = True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(restore_best_weights = True,\n",
        "                                                  patience = 3)"
      ],
      "metadata": {
        "id": "8AFIptITS9NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.compile(loss = 'binary_crossentropy',\n",
        "                   optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
        "                   metrics = [\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "pBjhZwewTPFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet_model.fit(X_train, y_train\n",
        "                         epochs = 8,\n",
        "                         validation_data = (X_test, y_test),\n",
        "                         callbacks = [model_ckp, early_stoppint])"
      ],
      "metadata": {
        "id": "X0cOt2_bUD_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/cracked_concrete.jpg'\n",
        "new_img = load_img(img_path, target_size = IMG_SIZE)\n",
        "new_img = img_to_array(new_img) / 255.0"
      ],
      "metadata": {
        "id": "SQDK9gZlVQw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = unet_model(tf.expand_dims(new_img, axis = 0))"
      ],
      "metadata": {
        "id": "IAiBCn1cVfNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_img = '/content/cracked_concrete.jpg'\n",
        "or_img = plt.imread(original_img)\n",
        "or_img = load_img(original_img, target_size = IMG_SIZE)\n",
        "or_img = img_to_array(or_img) / 255.0\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(or_img)\n",
        "plt.title('Original Image')\n",
        "plt.subplot(122)\n",
        "plt.imshow(tf.squeeze(pred), cmap = 'binary')\n",
        "plt.title('Predicted Segmentation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "47fOjpq0VmQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWE4qxj0WiSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}